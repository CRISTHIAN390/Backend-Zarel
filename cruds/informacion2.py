from models.informacion import OBJCategoria
import google.generativeai as genai
import re
from collections import deque

# Configuraci√≥n de la API de Google Generative AI
API_KEY = "AIzaSyCmjRN_xL07aRkftfoUba3nHW-_hkrZwnc"
genai.configure(api_key=API_KEY)
 
 
 
# Solo mantenemos el patr√≥n de saludos para respuesta r√°pida
PATRON_SALUDO = re.compile(r'\b(hola|hl|mano|hi|hey|buenos dias|que tal|buenas|buenas tardes|buenas noches|saludos)\b')
RESPUESTA_SALUDO = "¬°Hola! Soy Pelotero AI. ¬øEn qu√© puedo ayudarte hoy?"
RESPUESTA_ERROR = "Ups... algo sali√≥ mal al procesar tu mensaje üòì. ¬øPodr√≠as intentarlo otra vez, por favor?"


def asistentechatbot2(mensaje_usuario: str) -> str:
    """
    Funci√≥n principal que procesa el mensaje del usuario y devuelve una respuesta.
    No mantiene estado entre llamadas (sin memoria).
    """
    try:
        # Normalizar el texto (conversi√≥n r√°pida a min√∫sculas)
        mensaje_limpio = mensaje_usuario.lower().strip()
        
        # Solo verificamos si es un saludo con respuesta r√°pida
        if PATRON_SALUDO.search(mensaje_limpio):
            return RESPUESTA_SALUDO
        
        # Para todo lo dem√°s, dejamos que la IA interprete y genere la respuesta
        return generar_respuesta_ia(mensaje_usuario)
            
    except Exception as e:
        # Manejo de errores simplificado
        return RESPUESTA_ERROR

def generar_respuesta_ia(consulta: str) -> str:
    """
    Utiliza la IA para interpretar y generar una respuesta apropiada,
    ya sea sobre la radio o sobre cualquier otro tema.
    """

    try:
        # Configuraci√≥n para Gemini
        model = genai.GenerativeModel(
            'gemini-1.5-flash',
            generation_config={
                "temperature": 0.7,
                "top_p": 0.95,
                "top_k": 40
            }
        )

        
        # Prompt completo con contexto de la radio
        prompt = f"""
        Act√∫a como Pelotero AI, el asistente virtual de canchas deportivas, responde a la siguiente consulta con un tono amigable, claro y profesional: 
        "{consulta}"
        """
        response = model.generate_content(prompt)
        if response.text:
            return response.text.strip()
        else:
            return "Lo siento, no puedo responder a esa consulta en este momento"
    except Exception as e:
            return "Disculpa, no pude generar una respuesta"


